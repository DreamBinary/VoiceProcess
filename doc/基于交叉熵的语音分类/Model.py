import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.utils import spectral_norm



'''
模型来自
https://github.com/jjery2243542/adaptive_voice_conversion
《One-shot Voice Conversion by Separating Speaker and Content Representations with Instance Normalization》

'''



def pad_layer(inp, layer, pad_type='reflect'):
    kernel_size = layer.kernel_size[0]
    if kernel_size % 2 == 0:
        pad = (kernel_size//2, kernel_size//2 - 1)
    else:
        pad = (kernel_size//2, kernel_size//2)
    # padding
    inp = F.pad(inp,
            pad=pad,
            mode=pad_type)
    out = layer(inp)
    return out

def pixel_shuffle_1d(inp, scale_factor=2):
    batch_size, channels, in_width = inp.size()
    channels //= scale_factor
    out_width = in_width * scale_factor
    inp_view = inp.contiguous().view(batch_size, channels, scale_factor, in_width)
    shuffle_out = inp_view.permute(0, 1, 3, 2).contiguous()
    shuffle_out = shuffle_out.view(batch_size, channels, out_width)
    return shuffle_out

def upsample(x, scale_factor=2):
    x_up = F.interpolate(x, scale_factor=scale_factor, mode='nearest')
    return x_up

def flatten(x):
    out = x.contiguous().view(x.size(0), x.size(1) * x.size(2))
    return out


def conv_bank(x, module_list, act, pad_type='reflect'):
    outs = []
    for layer in module_list:
        out = act(pad_layer(x, layer, pad_type))
        outs.append(out)
    out = torch.cat(outs + [x], dim=1)
    #print("conv_bank out shape",out.shape)
    return out

def get_act(act):
    if act == 'relu':
        return nn.ReLU()
    elif act == 'lrelu':
        return nn.LeakyReLU()
    else:
        return nn.ReLU()

class MLP(nn.Module):
    def __init__(self, c_in, c_h, n_blocks, act, sn):
        super(MLP, self).__init__()
        self.act = get_act(act)
        self.n_blocks = n_blocks
        f = spectral_norm if sn else lambda x: x
        self.in_dense_layer = f(nn.Linear(c_in, c_h))
        self.first_dense_layers = nn.ModuleList([f(nn.Linear(c_h, c_h)) for _ in range(n_blocks)])
        self.second_dense_layers = nn.ModuleList([f(nn.Linear(c_h, c_h)) for _ in range(n_blocks)])

    def forward(self, x):
        h = self.in_dense_layer(x)
        for l in range(self.n_blocks):
            y = self.first_dense_layers[l](h)
            y = self.act(y)
            y = self.second_dense_layers[l](y)
            y = self.act(y)
            h = h + y
        return h

class SpeakerEncoder(nn.Module):
    def __init__(self, c_in, c_h, c_out, kernel_size,
            bank_size, bank_scale, c_bank,
            n_conv_blocks, n_dense_blocks,
            subsample, act, dropout_rate,num_class):
        super(SpeakerEncoder, self).__init__()
        self.c_in = c_in
        self.c_h = c_h
        self.c_out = c_out
        self.kernel_size = kernel_size
        self.n_conv_blocks = n_conv_blocks
        self.n_dense_blocks = n_dense_blocks
        self.subsample = subsample
        self.act = get_act(act)
        self.conv_bank = nn.ModuleList(
                [nn.Conv1d(c_in, c_bank, kernel_size=k) for k in range(bank_scale, bank_size + 1, bank_scale)])
        in_channels = c_bank * (bank_size // bank_scale) + c_in
        self.in_conv_layer = nn.Conv1d(in_channels, c_h, kernel_size=1)
        self.first_conv_layers = nn.ModuleList([nn.Conv1d(c_h, c_h, kernel_size=kernel_size) for _ \
                in range(n_conv_blocks)])
        self.second_conv_layers = nn.ModuleList([nn.Conv1d(c_h, c_h, kernel_size=kernel_size, stride=sub)
            for sub, _ in zip(subsample, range(n_conv_blocks))])
        self.pooling_layer = nn.AdaptiveAvgPool1d(1)
        self.first_dense_layers = nn.ModuleList([nn.Linear(c_h, c_h) for _ in range(n_dense_blocks)])
        self.second_dense_layers = nn.ModuleList([nn.Linear(c_h, c_h) for _ in range(n_dense_blocks)])
        self.output_layer = nn.Linear(c_h, c_out)
        self.dropout_layer = nn.Dropout(p=dropout_rate)

        self.cls_layer  = nn.Linear(c_out,num_class)

    def conv_blocks(self, inp):
        out = inp
        # convolution blocks
        for l in range(self.n_conv_blocks):
            y = pad_layer(out, self.first_conv_layers[l])
            y = self.act(y)
            y = self.dropout_layer(y)
            y = pad_layer(y, self.second_conv_layers[l])
            y = self.act(y)
            y = self.dropout_layer(y)
            if self.subsample[l] > 1:
                out = F.avg_pool1d(out, kernel_size=self.subsample[l], ceil_mode=True)
            out = y + out
            #print(out.shape)
        return out

    def dense_blocks(self, inp):
        out = inp
        # dense layers
        for l in range(self.n_dense_blocks):
            y = self.first_dense_layers[l](out)
            y = self.act(y)
            y = self.dropout_layer(y)
            y = self.second_dense_layers[l](y)
            y = self.act(y)
            y = self.dropout_layer(y)
            out = y + out
        return out

    def forward(self, x):
        #print("--- spk encoder ---")
        out = conv_bank(x, self.conv_bank, act=self.act)
        # dimension reduction layer
        out = pad_layer(out, self.in_conv_layer)
        out = self.act(out)
        # conv blocks
        out = self.conv_blocks(out)
    
        # avg pooling
        out = self.pooling_layer(out).squeeze(2)

        #print(out.shape)
        # dense blocks
        out = self.dense_blocks(out)

        
        out = self.output_layer(out)
        #print("---")
        out = self.cls_layer(out)
        return out

    def look_shape_forward(self, x):
        print("--- spk encoder ---")
        print("输入数据维度:x",x.shape)
        out = conv_bank(x, self.conv_bank, act=self.act)
        # dimension reduction layer
        out = pad_layer(out, self.in_conv_layer)
        out = self.act(out)
        print("经过conv bank",out.shape)
        # conv blocks
        out = self.conv_blocks(out)
        print("经过多个卷积层：",out.shape)
        # avg pooling
        out = self.pooling_layer(out).squeeze(2)
        print("经过一个时间维度的池化层：",out.shape)

        print(out.shape)
        # dense blocks
        out = self.dense_blocks(out)
        print("经过多个线性层：",out.shape)
        out = self.output_layer(out)
        #print("---")
        out = self.cls_layer(out)
        print("经过分类层：",out.shape)
        return out


def testmodel():
    '''
    测试一下写的模型 能不能正常输入输出
    '''
    model_params_config = {"SpeakerEncoder":
                               {"c_in": 513,
                                "c_h": 128,
                                "c_out": 128,
                                "kernel_size": 5,
                                "bank_size": 8,
                                "bank_scale": 1,
                                "c_bank": 128,
                                "n_conv_blocks": 6,
                                "n_dense_blocks": 3,
                                "subsample": [1, 2, 1,2  , 1, 2],  ## 下采样的主要功能：缩小时间帧
                                "act": 'relu',
                                "dropout_rate": 0,
                                "num_class":3}
                           }
    speaker_clsmodel = SpeakerEncoder(**model_params_config['SpeakerEncoder']) ## 模型的定义
    a = torch.rand(3,513,200) ## 输入 频谱特征 
    
    #a = torch.rand(3,25000) ## 时域数据
    out = speaker_clsmodel(a)  ## 输入给模型
    out = speaker_clsmodel.look_shape_forward(a)

if __name__ == '__main__':
    testmodel()
